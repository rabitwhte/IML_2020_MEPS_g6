{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import dalex as dx\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle_in = open(\"MEPS_xgb_model_final_v2_cat_vars_str.pickle\", \"rb\")\n",
    "reg_xgb = pickle.load(pickle_in) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/MEPS_data_preprocessed_train.csv\n",
      "../../data/MEPS_data_preprocessed_test.csv\n"
     ]
    }
   ],
   "source": [
    "def transform_target_log3(data, target_name):\n",
    "    val = data[target_name].values\n",
    "    return np.array([0 if v == 0 else np.log(v) / np.log(3) for v in val])\n",
    "\n",
    "def read_x_y(path, target_name):\n",
    "    print(path)\n",
    "    data = pd.read_csv(path)\n",
    "    data[target_name] = transform_target_log3(data, target_name)\n",
    "    X = data.drop(columns = target_name)\n",
    "    y = data[target_name]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def get_categorical_features(data):\n",
    "    num_unique = data.nunique()\n",
    "    categorical_features = num_unique[num_unique <= 10].index.tolist()\n",
    "    # Remove variables from categorical features list that can be treated as continuous\n",
    "    for col in [\"POVCAT15\", \"RTHLTH31\", \"MNHLTH31\"]:\n",
    "        categorical_features.remove(col)\n",
    "    return categorical_features\n",
    "\n",
    "path = \"../../data/MEPS_data_preprocessed\"\n",
    "x_train, y_train = read_x_y(path + \"_train.csv\", \"HEALTHEXP\")\n",
    "x_test, y_test = read_x_y(path + \"_test.csv\", \"HEALTHEXP\")\n",
    "\n",
    "\n",
    "categorical_features = get_categorical_features(x_train)\n",
    "numerical_features= [f for f in x_train.columns if f not in categorical_features]\n",
    "\n",
    "for f in categorical_features:\n",
    "    x_train[f] = x_train[f].astype(\"str\")\n",
    "    x_test[f] = x_test[f].astype(\"str\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reset parameter is False but there is no n_features_in_ attribute. Is this estimator fitted?\n",
      "The reset parameter is False but there is no n_features_in_ attribute. Is this estimator fitted?\n"
     ]
    }
   ],
   "source": [
    "# Creating dalex explainer\n",
    "exp_xgb = dx.Explainer(reg_xgb, x_train, y_train, label = \"MEPS\", verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating list of variables describing diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HIBPDX', 'CHDDX', 'ANGIDX', 'MIDX', 'OHRTDX', 'STRKDX', 'EMPHDX', 'CHOLDX', 'CANCERDX', 'DIABDX', 'ARTHDX', 'ASTHDX', 'ADHDADDX']\n"
     ]
    }
   ],
   "source": [
    "dis_inx = [x for x in x_train.columns.tolist() if 'DX' in x]\n",
    "print(dis_inx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Getting patients with a given disease\n",
    "dis_dict = {x: [] for x in dis_inx}\n",
    "\n",
    "def get_patients_with_diseases(dis_name: str):\n",
    "    for index, row in x_train.iterrows():\n",
    "        if row[dis_name] == '1':\n",
    "            dis_dict[dis_name].append(index)\n",
    "\n",
    "for disease in dis_inx:\n",
    "    get_patients_with_diseases(disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creating random subset of patients for every disease\n",
    "def get_random_subset_of_patients(size: int):\n",
    "    dis_subset = {x: [] for x in dis_inx}\n",
    "    for dis in dis_dict:\n",
    "        dis_subset[dis] = random.sample(dis_dict[dis], min(size, len(dis_dict[dis])))\n",
    "    return dis_subset\n",
    "\n",
    "dis_dict_subset = get_random_subset_of_patients(50)\n",
    "\n",
    "def get_distinct_patient_no(dis_with_patient: dict):\n",
    "    list_patient_no = [no for key in dis_with_patient for no in dis_with_patient[key]]\n",
    "    return list(set(list_patient_no))\n",
    "\n",
    "patient_no = get_distinct_patient_no(dis_dict_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate shap results\n",
    "df_res_sh = pd.DataFrame(columns=[\"Index\", \"Dis\", \"Sh\"])\n",
    "\n",
    "def get_shap_values(inx, df):\n",
    "    sh_res = exp_xgb.predict_parts(pd.DataFrame(x_train.iloc[[inx]]), type='shap')\n",
    "    for dis in dis_inx:\n",
    "        if inx in dis_dict_subset[dis]:\n",
    "            val = sh_res.result.loc[sh_res.result[\"variable\"]== f\"{dis} = 1\"]['contribution'].mean()\n",
    "            df = df.append({'Index': inx, 'Dis': dis, 'Sh': val}, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "# with Pool(4) as p:\n",
    "#     p.map(gef_shap_values, patient_no)\n",
    "\n",
    "for no in patient_no:\n",
    "    df_res_sh = get_shap_values(no, df_res_sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Reading saved shap values from file\n",
    "\n",
    "df_res_sh = pd.DataFrame(columns=[\"Index\", \"Dis\", \"Sh\"])\n",
    "\n",
    "with open('patients_shap_50.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        if not re.match(\"^[0-9 ]+$\", line):\n",
    "            parts = re.split('\\s|(?<!\\d)[,.](?!\\d)', line)\n",
    "            if len(parts) >= 3:\n",
    "                df_res_sh = df_res_sh.append({'Index': parts[0], 'Dis': parts[1], 'Sh': float(parts[2])}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average shap value for each variable describing disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIABDX 0.633\n",
      "ADHDADDX 0.592\n",
      "ASTHDX 0.424\n",
      "CANCERDX 0.375\n",
      "CHOLDX 0.338\n",
      "HIBPDX 0.275\n",
      "CHDDX 0.165\n",
      "ARTHDX 0.157\n",
      "ANGIDX 0.091\n",
      "STRKDX 0.087\n",
      "EMPHDX 0.078\n",
      "OHRTDX 0.04\n",
      "MIDX 0.012\n"
     ]
    }
   ],
   "source": [
    "# Calculating mean shap value for each disease\n",
    "df_sh_mean = { n : df_res_sh.loc[df_res_sh['Dis'] == n, 'Sh'].mean() for n in dis_inx }\n",
    "d_view = [(k, v) for k, v in sorted(df_sh_mean.items(), key=lambda x: x[1], reverse=True)]\n",
    "for dis, val in d_view:\n",
    "    print(dis, round(val, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming the data input by deleting all disease related variables and created new column called POSVT (POSitiVe Tested) that is a weighted sum of positive disease diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Adding column about positive diagnosed diseases with weighted values\n",
    "fn = lambda row: sum([float(row[n]) * df_sh_mean[n] for n in dis_inx if int(row[n]) == 1])\n",
    "col_train = x_train.apply(fn, axis=1)\n",
    "col_test = x_test.apply(fn, axis=1)\n",
    "x_train = x_train.assign(POSVT=col_train.values)\n",
    "x_test = x_test.assign(POSVT=col_test.values)\n",
    "numerical_features.append(\"POSVT\")\n",
    "# Removing columns about diseases\n",
    "x_train =  x_train.drop(dis_inx, 1)\n",
    "x_test = x_test.drop(dis_inx, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cat_inx = categorical_features\n",
    "for x in dis_inx:\n",
    "    cat_inx.remove(x)\n",
    "\n",
    "numerical_features.append(\"POSVT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def print_model_results(y_train, y_pred_train, y_test, y_pred_test):\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    rmse_train = np.sqrt(mse_train)\n",
    "\n",
    "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "    rmse_test = np.sqrt(mse_test)\n",
    "    print(\"Training: \\nRMSE: \", rmse_train, \" | MAE: \", mean_absolute_error(y_train, y_pred_train), \" | R^2: \", r2_score(y_train, y_pred_train), \"\\n\")\n",
    "    print(\"Test: \\nRMSE: \", rmse_test, \" | MAE: \", mean_absolute_error(y_test, y_pred_test), \" | R^2: \", r2_score(y_test, y_pred_test), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB model trained on newly created data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB\n",
      "Training: \n",
      "RMSE:  2.0214149777806076  | MAE:  1.499952605147166  | R^2:  0.46410967040653717 \n",
      "\n",
      "Test: \n",
      "RMSE:  2.164473490869821  | MAE:  1.6024235179904278  | R^2:  0.37751378269478897 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical_transformer = Pipeline(\n",
    "    steps = [\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown = \"ignore\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "numerical_transformer = Pipeline(\n",
    "    steps = [\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        (\"cat\", categorical_transformer, cat_inx),\n",
    "        (\"num\", numerical_transformer, numerical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "regressor = GradientBoostingRegressor(n_estimators = 76,\n",
    "                                    max_depth = 5,\n",
    "                                    min_samples_split = 3,\n",
    "                                    min_samples_leaf = 6,\n",
    "                                    random_state = 123)\n",
    "\n",
    "reg_xgb_2 = Pipeline(steps = [(\"preprocessor\", preprocessor),\n",
    "                      (\"regressor\", regressor)])\n",
    "\n",
    "reg_xgb_2.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "y_pred_train = reg_xgb_2.predict(x_train)\n",
    "y_pred_test = reg_xgb_2.predict(x_test)\n",
    "print(\"XGB\")\n",
    "print_model_results(y_train, y_pred_train, y_test, y_pred_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression model on newly crated dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge\n",
      "Training: \n",
      "RMSE:  2.27228977432158  | MAE:  1.7188136184013174  | R^2:  0.32283829531254704 \n",
      "\n",
      "Test: \n",
      "RMSE:  2.2523752024218004  | MAE:  1.6952850671349031  | R^2:  0.3259274029288295 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear model with the same  weights as in xgb model\n",
    "param = {'alpha': [1e-15, 1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 1, 5, 10, 20, 30, 40, 50, 100, 150, 200]}\n",
    "\n",
    "ridge = Ridge()\n",
    "ridge_regressor = GridSearchCV(ridge, param, cv=5)\n",
    "ridge_regressor.fit(x_train, y_train)\n",
    "pred_rr_test = ridge_regressor.predict(x_test)\n",
    "pred_rr_train = ridge_regressor.predict(x_train)\n",
    "print(\"Ridge\")\n",
    "print_model_results(y_train, pred_rr_train, y_test, pred_rr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGION -0.08777809144112808\n",
      "AGE31X 0.013217952850652583\n",
      "GENDER 0.40229406366393794\n",
      "RACE3 -0.7130774403681513\n",
      "MARRY31X 0.0035315946085666544\n",
      "EDRECODE 0.02883818882171903\n",
      "FTSTU31X -0.08274977521771627\n",
      "ACTDTY31 0.134429503019919\n",
      "HONRDC31 0.19067226651806193\n",
      "RTHLTH31 0.21452552614696246\n",
      "MNHLTH31 -0.00406274548457693\n",
      "CHBRON31 0.11579767078360631\n",
      "JTPAIN31 -0.32371708977277786\n",
      "ARTHTYPE 0.04068768058768482\n",
      "PREGNT31 0.18463554753828268\n",
      "WLKLIM31 -0.13075075187923935\n",
      "ACTLIM31 -0.16228132160489\n",
      "SOCLIM31 -0.014744991263111235\n",
      "COGLIM31 -0.2827933605036464\n",
      "DFHEAR42 -0.03941409165137288\n",
      "DFSEE42 -0.06241758519972284\n",
      "ADSMOK42 0.5631056619444823\n",
      "PCS42 -0.019310220385490257\n",
      "MCS42 -0.0049781569185487025\n",
      "K6SUM42 0.03675186838436542\n",
      "PHQ242 0.01817890791799011\n",
      "EMPST31 0.05807524208151758\n",
      "POVCAT15 0.1041849957762876\n",
      "INSCOV15 -0.7378166881989838\n",
      "INCOME_M 3.2952350111729098e-06\n",
      "POSVT 1.4656596710992793\n"
     ]
    }
   ],
   "source": [
    "# Coefficients weight in rdige regression model\n",
    "for name, coef in zip(x_train.columns.tolist() , ridge_regressor.best_estimator_.coef_):\n",
    "    print(name, coef)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}